{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PnSwTBBkPDk7"
   },
   "source": [
    "# Clasificacion con  RNN multi-capa\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdiaN2pMPDk-"
   },
   "source": [
    "## 1 - Importar modulos ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nraWPuCqPDlA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bbw5OLnSPDlM"
   },
   "source": [
    "## 2 - Dataset ##\n",
    "Importar dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TE7rMmXYPDlO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension           ...             worst radius  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer=load_breast_cancer()\n",
    "\n",
    "df= pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxSFlgJiPDlS"
   },
   "source": [
    "Utilizar los metodos `.head(), .describe(), . info()` para ver el contenido del dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      "mean radius                569 non-null float64\n",
      "mean texture               569 non-null float64\n",
      "mean perimeter             569 non-null float64\n",
      "mean area                  569 non-null float64\n",
      "mean smoothness            569 non-null float64\n",
      "mean compactness           569 non-null float64\n",
      "mean concavity             569 non-null float64\n",
      "mean concave points        569 non-null float64\n",
      "mean symmetry              569 non-null float64\n",
      "mean fractal dimension     569 non-null float64\n",
      "radius error               569 non-null float64\n",
      "texture error              569 non-null float64\n",
      "perimeter error            569 non-null float64\n",
      "area error                 569 non-null float64\n",
      "smoothness error           569 non-null float64\n",
      "compactness error          569 non-null float64\n",
      "concavity error            569 non-null float64\n",
      "concave points error       569 non-null float64\n",
      "symmetry error             569 non-null float64\n",
      "fractal dimension error    569 non-null float64\n",
      "worst radius               569 non-null float64\n",
      "worst texture              569 non-null float64\n",
      "worst perimeter            569 non-null float64\n",
      "worst area                 569 non-null float64\n",
      "worst smoothness           569 non-null float64\n",
      "worst compactness          569 non-null float64\n",
      "worst concavity            569 non-null float64\n",
      "worst concave points       569 non-null float64\n",
      "worst symmetry             569 non-null float64\n",
      "worst fractal dimension    569 non-null float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension           ...             \\\n",
       "count     569.000000              569.000000           ...              \n",
       "mean        0.181162                0.062798           ...              \n",
       "std         0.027414                0.007060           ...              \n",
       "min         0.106000                0.049960           ...              \n",
       "25%         0.161900                0.057700           ...              \n",
       "50%         0.179200                0.061540           ...              \n",
       "75%         0.195700                0.066120           ...              \n",
       "max         0.304000                0.097440           ...              \n",
       "\n",
       "       worst radius  worst texture  worst perimeter   worst area  \\\n",
       "count    569.000000     569.000000       569.000000   569.000000   \n",
       "mean      16.269190      25.677223       107.261213   880.583128   \n",
       "std        4.833242       6.146258        33.602542   569.356993   \n",
       "min        7.930000      12.020000        50.410000   185.200000   \n",
       "25%       13.010000      21.080000        84.110000   515.300000   \n",
       "50%       14.970000      25.410000        97.660000   686.500000   \n",
       "75%       18.790000      29.720000       125.400000  1084.000000   \n",
       "max       36.040000      49.540000       251.200000  4254.000000   \n",
       "\n",
       "       worst smoothness  worst compactness  worst concavity  \\\n",
       "count        569.000000         569.000000       569.000000   \n",
       "mean           0.132369           0.254265         0.272188   \n",
       "std            0.022832           0.157336         0.208624   \n",
       "min            0.071170           0.027290         0.000000   \n",
       "25%            0.116600           0.147200         0.114500   \n",
       "50%            0.131300           0.211900         0.226700   \n",
       "75%            0.146000           0.339100         0.382900   \n",
       "max            0.222600           1.058000         1.252000   \n",
       "\n",
       "       worst concave points  worst symmetry  worst fractal dimension  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9JqTgNsEPDlZ"
   },
   "source": [
    "Elegir los datos de entrenminento, test y la variable a predecir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nN2m6t3bbvhJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (455, 30)\n",
      "X_test shape : (114, 30)\n",
      "y_train shape : (455, 1)\n",
      "y_test shape : (114, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X =cancer.data\n",
    "y= cancer.target\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.2, shuffle=True)\n",
    "\n",
    "print(f'X_train shape : {X_train.shape}')\n",
    "print(f'X_test shape : {X_test.shape}')\n",
    "\n",
    "y_train=y_train.reshape(-1,1)\n",
    "y_test=y_test.reshape(-1,1)\n",
    "print(f'y_train shape : {y_train.shape}')\n",
    "print(f'y_test shape : {y_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OYNWNXXGPDmC"
   },
   "source": [
    "## 3 - Modelo de la Red Neuronal\n",
    "\n",
    "\n",
    "\n",
    "**Modelo**:\n",
    "\n",
    "Dados los datos de entranamiento  $x^{(i)}$ computa:\n",
    "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1] (i)}\\tag{1}$$ \n",
    "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})\\tag{2}$$\n",
    "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2] (i)}\\tag{3}$$\n",
    "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})\\tag{4}$$\n",
    "$$y^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{if } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{otherwise } \\end{cases}\\tag{5}$$\n",
    "\n",
    "Calcula el error $J$ (Formula no vectorizada) : \n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} ( y^{(i)}\\log(a^{[2] (i)}) + (1-y^{(i)})\\log(1- a^{[2] (i)})  )  \\tag{6}$$\n",
    "\n",
    "\n",
    "\n",
    "**Recordatorio**: El metodo general para construir una RNN es:\n",
    "    1. Define la estructura de la red neuronal ( # num. entradas,  # nodos | hidden units, etc). \n",
    "    2. Inicializa los parametros del modelo (W, b)\n",
    "    3. Loop:\n",
    "        - Implementa  forward propagation\n",
    "        - Computa el Error\n",
    "        - Implementa backward propagation para obtener los gradients\n",
    "        - Encuentra los  parametros (gradiente descente)\n",
    "    4. Haz la prediccion (Ecuacion 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6lOYwJ6PDmC"
   },
   "source": [
    "### 4.1 - Define la estructura de la RNN  ####\n",
    "\n",
    "**Estructura**: Definir tres variables:\n",
    "    - n_x: Tamaño de la capa de entrada o datos \n",
    "    - n_h: Tamaño de los nodos o hidden units  \n",
    "    - n_y: Tamaño de la salida \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "9yguW0LyPDmD"
   },
   "outputs": [],
   "source": [
    "# Esctructura de la red neuronal\n",
    "\n",
    "def layer_sizes(X, Y,n_h):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    X -- Forma de los datos de entrenamineto (Tamaño de entrada, numero de ejemplos)\n",
    "    Y -- Forma de la variable a predecir (Tamaño , numero de ejemplos)\n",
    "    \n",
    "    Returns:\n",
    "    n_x numero de caracteristicas de tu dataset N^[0]\n",
    "    n_h numero de hidden units\n",
    "    n_y forma de la salida\n",
    "    \"\"\"\n",
    "    # Tu codigo \n",
    "    n_x= X.shape[1] # numero de caracteristicas de tu dataset N^[0]\n",
    "    n_h= 4\n",
    "    n_y= Y.shape[1]\n",
    "    \n",
    "    \n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r13WvXQsPDmM"
   },
   "source": [
    "### 4.2 - Inicializar  los parametros del modelo ####\n",
    "\n",
    "**Instruciones**:\n",
    "\n",
    "-  Inicializa los weights con valores random. \n",
    "    - Usa: `np.random.randn(a,b) * 0.01` Se multiplica por 0.01 para escalarlo .\n",
    "- Inicializa el  bias en un vector de ceros. \n",
    "    - Use: `np.zeros((a,b))` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vnU5rM7BPDmN"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    n_x \n",
    "    n_h \n",
    "    n_y \n",
    "    \n",
    "    Returns:\n",
    "    parametros -- python diccionario que  contiene los parametros:\n",
    "                    W1 -- weight matrix con forma (n_h, n_x)\n",
    "                    b1 -- bias vector con forma (n_h, 1)\n",
    "                    W2 -- weight matrix con forma (n_y, n_h)\n",
    "                    b2 -- bias vector con forma (n_y, 1)\n",
    "    \"\"\"\n",
    "    # Tu codigo \n",
    "    np.random.seed(2) # mismo conjunto de numeros aleatorios \n",
    "    \n",
    "    W1 = np.random.randn(n_h,n_x)*0.01\n",
    "    b1=np.random.randn(n_h,1)\n",
    "    W2 = np.random.randn(n_y,n_h)*0.01\n",
    "    b2=np.random.randn(n_y,1)\n",
    "    \n",
    "    parametros={'W1':W1,'b1':b1,'W2':W2, 'b2':b2}\n",
    "    \n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y,n_h))\n",
    "    assert (b2.shape ==(n_y, 1))\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4HSKIGlNPDmT"
   },
   "source": [
    "### 4.3 -  Loop \n",
    "\n",
    "#### Implementar `forward_propagation()`.\n",
    "Dados los datos de entranamiento  $x^{(i)}$ computa:\n",
    "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1] (i)}\\tag{1}$$ \n",
    "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})\\tag{2}$$\n",
    "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2] (i)}\\tag{3}$$\n",
    "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})\\tag{4}$$\n",
    "$$y^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{if } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{otherwise } \\end{cases}\\tag{5}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "X1OUHW08PDmT"
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parametros):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    X -- Datos de entrada (n_x, m)\n",
    "    parametros \n",
    "    \n",
    "    Returns:\n",
    "    A2 -- salida\n",
    "    cache -- Un diccionario que contenga \"Z1\", \"A1\", \"Z2\" and \"A2\" \n",
    "    \"\"\"\n",
    "    # Tu codigo\n",
    "    W1 =parametros['W1']\n",
    "    b1 =parametros['b1']\n",
    "    W2 =parametros['W2']\n",
    "    b2 =parametros['b2']\n",
    "    \n",
    "    # Forward Propagation \n",
    "    Z1 = W1 @ X.T + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = W2 @ A1.T + b2 \n",
    "    # Sigmoid function\n",
    "    A2 = 1.0/(1.0 + np.exp(- Z2))\n",
    "    \n",
    "    cache= {'Z1':Z1, 'A1': A1,'Z2':Z2,'A2':A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5JdXj3SwPDma"
   },
   "source": [
    "#### Funcion de Error | Loss | Cost\n",
    "\n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large{(} \\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right) \\large{)} \\small\\tag{13}$$\n",
    "\n",
    "**Ejercicio**: Implementa `compute_cost()` para obtener el error $J$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sDGDyvhaPDmb"
   },
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y):\n",
    "    \"\"\"\n",
    "    Computa  cross-entropy cost dada la ecuacion (13)\n",
    "    \n",
    "    Argumentos:\n",
    "    A2 -- Forma (1, numero de ejemplos)\n",
    "    Y -- variable categorica o y_train (1, numero de ejemplos)\n",
    "    parametros --  W1, b1, W2 y b2\n",
    "    \n",
    "    Returns:\n",
    "    loss\n",
    "    \"\"\"\n",
    "    m=Y.shape[0]\n",
    "    \n",
    "    # Cross entropy loss\n",
    "    loss = -np.sum(Y.T@np.log(A2) + (1-Y).T @ np.log(1-A2))/m\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sa8fXanBPDmh"
   },
   "source": [
    "#### Backward propagation\n",
    "\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } = \\frac{1}{m} (a^{[2](i)} - y^{(i)})$\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial W_2 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } a^{[1] (i) T} $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial b_2 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)}}}$\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} } =  W_2^T \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} }{ \\partial W_1 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} }  X^T $\n",
    "\n",
    "$\\frac{\\partial \\mathcal{J} _i }{ \\partial b_1 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)}}}$\n",
    "\n",
    "- Nota el $*$ denota elementwise multiplication.\n",
    "- Otra notacion mas sencilla:\n",
    "    - dW1 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_1 }$\n",
    "    - db1 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_1 }$\n",
    "    - dW2 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_2 }$\n",
    "    - db2 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_2 }$\n",
    "    \n",
    "Forma mas sencilla: \n",
    "\n",
    "\n",
    "$$dz^{[2] } =  A^{[2]}  - Y \\tag{1}$$ \n",
    "\n",
    "$$dW^{[2] } = \\frac{1}{m}dz^{[2]}A^{[1]}\\tag{2}$$\n",
    "\n",
    "$$db^{[2] } = \\frac{1}{m}\\sum_i dz^{[2]} \\tag{3}$$\n",
    "\n",
    "$$dz^{[1] } =  W^{[2]}dz^{[2] }*g^{'[1]}(Z^{[1]}) \\tag{4}$$ \n",
    "\n",
    "\n",
    "$$dW^{[1] } = \\frac{1}{m}dz^{[1]}X^T \\tag{5}$$\n",
    "\n",
    "\n",
    "$$db^{[1] } = \\frac{1}{m}\\sum_i dz^{[1]} \\tag{6}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "uqB41MNdPDmh"
   },
   "outputs": [],
   "source": [
    "def backward_propagation(parametros, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Implementa el backward propagation \n",
    "    \n",
    "    Argumentos:\n",
    "    parametros  \n",
    "    cache -- dictionario con  \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
    "    X \n",
    "    Y shape (m,F)  \n",
    "    \n",
    "    Returns:\n",
    "    grads -- python diccionario que contiene los gradientes \n",
    "    \"\"\"\n",
    "    m= Y.shape[0]\n",
    "    \n",
    "    W1=parametros['W1']\n",
    "    W2=parametros['W2']\n",
    "    A1=cache['A1']\n",
    "    A2=cache['A2']\n",
    "    \n",
    "    # Backward Propagation\n",
    "    # layer 2\n",
    "    dZ2 =A2 - Y\n",
    "    dW2= (dZ2 @ A1.T)/m\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True)\n",
    "    # layer 1\n",
    "    dZ1= W2 @ dZ2 * (1 - np.power(A1,2))\n",
    "    dW1=(dZ1 @ X.T)/m\n",
    "    db1 = np.sum(dZ1,axis=1, keepdims=True)/m\n",
    "    \n",
    "    # Gradientes\n",
    "    grads= {'dW1':dW1,'db1':db1, 'dW2':dW2,'db2':db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zetahzehPDmm"
   },
   "source": [
    "#### Gradient descent \n",
    "\n",
    "$ \\theta = \\theta - \\alpha \\frac{\\partial J }{ \\partial \\theta }$ donde  $\\alpha$ es el learning rate y $\\theta$ representa un parametro.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "DARXmR3ePDmm"
   },
   "outputs": [],
   "source": [
    "def gradiente_descendiente(parametros, grads,n_iter, learning_rate = 0.01):\n",
    "    \"\"\"\n",
    "    Encuentra los parametros que produzcan el minimo error\n",
    "    \n",
    "    Argumentos:\n",
    "    parameters  \n",
    "    grads  \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python diccionario con los parametros actualizados  \n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        parametros['W1'] = parametros['W1'] - learning_rate*grads['dW1']\n",
    "        parametros['b1'] = parametros['b1'] - learning_rate*grads['db1']\n",
    "        parametros['W2'] = parametros['W2'] - learning_rate*grads['dW2']\n",
    "        parametros['b2'] = parametros['b2'] - learning_rate*grads['db2']\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6oiZpLd8PDms"
   },
   "source": [
    "### 4.4 - Integra  4.1, 4.2 y 4.3 en nn_model() ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TVOneQq_PDms"
   },
   "outputs": [],
   "source": [
    "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Argumentos:\n",
    "    X --  Datos de entrenamineto\n",
    "    Y -- Variable a predecir\n",
    "    n_h -- Tamaño de la hidden layer\n",
    "    num_iterations \n",
    "    print_cost -- si es True, print imprime el cost cada 1000 iteraciones\n",
    "    \n",
    "    Returns:\n",
    "    parametros -- Parametros aprendidos \n",
    "    \"\"\"\n",
    "    \n",
    "    return parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jH7g3x4MPDmz"
   },
   "source": [
    "### 4.5 Predicciones\n",
    "\n",
    "**Recordatorio**: predicciones = $y_{prediction} = \\mathbb 1 \\text{{activation > 0.5}} = \\begin{cases}\n",
    "      1 & \\text{if}\\ activation > 0.5 \\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases}$  \n",
    "    `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6-c5jR_SPDm0"
   },
   "outputs": [],
   "source": [
    "def predict(A2):\n",
    "    \"\"\"\n",
    "    \n",
    "    Argumentos:\n",
    "    parametros \n",
    "    X -- input data(n_x, m)\n",
    "    \n",
    "    Returns\n",
    "    predictions -- vector con  ( 0 / 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return predictions"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "RNN_multicapa.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
