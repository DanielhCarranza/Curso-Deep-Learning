{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_multicapa.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PnSwTBBkPDk7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Clasificacion con  RNN multi-capa\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "MdiaN2pMPDk-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1 - Importar modulos ##\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nraWPuCqPDlA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Codigo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bbw5OLnSPDlM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2 - Dataset ##\n",
        "Importar dataset "
      ]
    },
    {
      "metadata": {
        "id": "TE7rMmXYPDlO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dxSFlgJiPDlS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Utilizar los metodos `.head(), .describe(), . info()` para ver el contenido del dataset "
      ]
    },
    {
      "metadata": {
        "id": "UQaItB2laOlW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9JqTgNsEPDlZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Elegir los datos de entrenminento, test y la variable a predecir "
      ]
    },
    {
      "metadata": {
        "id": "nN2m6t3bbvhJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OYNWNXXGPDmC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3 - Modelo de la Red Neuronal\n",
        "\n",
        "\n",
        "\n",
        "**Modelo**:\n",
        "\n",
        "Dados los datos de entranamiento  $x^{(i)}$ computa:\n",
        "$$z^{[1] (i)} =  W^{[1]} x^{(i)} + b^{[1] (i)}\\tag{1}$$ \n",
        "$$a^{[1] (i)} = \\tanh(z^{[1] (i)})\\tag{2}$$\n",
        "$$z^{[2] (i)} = W^{[2]} a^{[1] (i)} + b^{[2] (i)}\\tag{3}$$\n",
        "$$\\hat{y}^{(i)} = a^{[2] (i)} = \\sigma(z^{ [2] (i)})\\tag{4}$$\n",
        "$$y^{(i)}_{prediction} = \\begin{cases} 1 & \\mbox{if } a^{[2](i)} > 0.5 \\\\ 0 & \\mbox{otherwise } \\end{cases}\\tag{5}$$\n",
        "\n",
        "Calcula el error $J$ (Formula no vectorizada) : \n",
        "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large\\left(\\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right)  \\large  \\right) \\small \\tag{6}$$\n",
        "\n",
        "\n",
        "\n",
        "**Recordatorio**: El metodo general para construir una RNN es:\n",
        "    1. Define la estructura de la red neuronal ( # num. entradas,  # nodos | hidden units, etc). \n",
        "    2. Inicializa los parametros del modelo (W, b)\n",
        "    3. Loop:\n",
        "        - Implementa  forward propagation\n",
        "        - Computa el Error\n",
        "        - Implementa backward propagation para obtener los gradients\n",
        "        - Encuentra los  parametros (gradiente descente)\n",
        "    4. Haz la prediccion (Ecuacion 5)\n"
      ]
    },
    {
      "metadata": {
        "id": "u6lOYwJ6PDmC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.1 - Define la estructura de la RNN  ####\n",
        "\n",
        "**Estructura**: Definir tres variables:\n",
        "    - n_x: Tamaño de la capa de entrada o datos \n",
        "    - n_h: Tamaño de los nodos o hidden units  \n",
        "    - n_y: Tamaño de la salida \n"
      ]
    },
    {
      "metadata": {
        "id": "9yguW0LyPDmD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def layer_sizes(X, Y,n_h):\n",
        "    \"\"\"\n",
        "    Argumentos:\n",
        "    X -- Forma de los datos de entrenamineto (Tamaño de entrada, numero de ejemplos)\n",
        "    Y -- Forma de la variable a predecir (Tamaño , numero de ejemplos)\n",
        "    \n",
        "    Returns:\n",
        "    n_x \n",
        "    n_h \n",
        "    n_y \n",
        "    \"\"\"\n",
        "    # Tu codigo \n",
        "    \n",
        "    \n",
        "    \n",
        "    return (n_x, n_h, n_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r13WvXQsPDmM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.2 - Inicializar  los parametros del modelo ####\n",
        "\n",
        "**Instruciones**:\n",
        "\n",
        "-  Inicializa los weights con valores random. \n",
        "    - Usa: `np.random.randn(a,b) * 0.01` Se multiplica por 0.01 para escalarlo .\n",
        "- Inicializa el  bias en un vector de ceros. \n",
        "    - Use: `np.zeros((a,b))` "
      ]
    },
    {
      "metadata": {
        "id": "vnU5rM7BPDmN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def initialize_parameters(n_x, n_h, n_y):\n",
        "    \"\"\"\n",
        "    Argumentos:\n",
        "    n_x \n",
        "    n_h \n",
        "    n_y \n",
        "    \n",
        "    Returns:\n",
        "    parametros -- python diccionario que  contiene los parametros:\n",
        "                    W1 -- weight matrix con forma (n_h, n_x)\n",
        "                    b1 -- bias vector con forma (n_h, 1)\n",
        "                    W2 -- weight matrix con forma (n_y, n_h)\n",
        "                    b2 -- bias vector con forma (n_y, 1)\n",
        "    \"\"\"\n",
        "    # Tu codigo     \n",
        "\n",
        "    return parametros"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4HSKIGlNPDmT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.3 -  Loop \n",
        "\n",
        "#### Implementar `forward_propagation()`.\n"
      ]
    },
    {
      "metadata": {
        "id": "X1OUHW08PDmT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def forward_propagation(X, parametros):\n",
        "    \"\"\"\n",
        "    Argumentos:\n",
        "    X -- Datos de entrada (n_x, m)\n",
        "    parametros \n",
        "    \n",
        "    Returns:\n",
        "    A2 -- salida\n",
        "    cache -- Un diccionario que contenga \"Z1\", \"A1\", \"Z2\" and \"A2\" \n",
        "    \"\"\"\n",
        "    # Tu codigo\n",
        "    \n",
        "    \n",
        "    return A2, cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5JdXj3SwPDma",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Funcion de Error | Loss | Cost\n",
        "\n",
        "$$J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\large{(} \\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right) \\large{)} \\small\\tag{13}$$\n",
        "\n",
        "**Ejercicio**: Implementa `compute_cost()` para obtener el error $J$.\n"
      ]
    },
    {
      "metadata": {
        "id": "sDGDyvhaPDmb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def compute_cost(A2, Y, parametros):\n",
        "    \"\"\"\n",
        "    Computa  cross-entropy cost dada la ecuacion (13)\n",
        "    \n",
        "    Argumentos:\n",
        "    A2 -- Forma (1, numero de ejemplos)\n",
        "    Y -- variable categorica o y_train (1, numero de ejemplos)\n",
        "    parametros --  W1, b1, W2 y b2\n",
        "    \n",
        "    Returns:\n",
        "    cost|\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sa8fXanBPDmh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Backward propagation\n",
        "\n",
        "\n",
        "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } = \\frac{1}{m} (a^{[2](i)} - y^{(i)})$\n",
        "\n",
        "$\\frac{\\partial \\mathcal{J} }{ \\partial W_2 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } a^{[1] (i) T} $\n",
        "\n",
        "$\\frac{\\partial \\mathcal{J} }{ \\partial b_2 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)}}}$\n",
        "\n",
        "$\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} } =  W_2^T \\frac{\\partial \\mathcal{J} }{ \\partial z_{2}^{(i)} } * ( 1 - a^{[1] (i) 2}) $\n",
        "\n",
        "$\\frac{\\partial \\mathcal{J} }{ \\partial W_1 } = \\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)} }  X^T $\n",
        "\n",
        "$\\frac{\\partial \\mathcal{J} _i }{ \\partial b_1 } = \\sum_i{\\frac{\\partial \\mathcal{J} }{ \\partial z_{1}^{(i)}}}$\n",
        "\n",
        "- Nota el $*$ denota elementwise multiplication.\n",
        "- Otra notacion mas sencilla:\n",
        "    - dW1 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_1 }$\n",
        "    - db1 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_1 }$\n",
        "    - dW2 = $\\frac{\\partial \\mathcal{J} }{ \\partial W_2 }$\n",
        "    - db2 = $\\frac{\\partial \\mathcal{J} }{ \\partial b_2 }$\n",
        "    \n",
        "Forma mas sencilla: \n",
        "\n",
        "\n",
        "$$dz^{[2] } =  A^{[2]}  - Y \\tag{1}$$ \n",
        "\n",
        "$$dW^{[2] } = \\frac{1}{m}dz^{[2]}A^{[1]}\\tag{2}$$\n",
        "\n",
        "$$db^{[2] } = \\frac{1}{m}\\sum_i dz^{[2]} \\tag{3}$$\n",
        "\n",
        "$$dz^{[1] } =  W^{[2]}dz^{[2] }*g^{'[1]}(Z^{[1]}) \\tag{4}$$ \n",
        "\n",
        "\n",
        "$$dW^{[1] } = \\frac{1}{m}dz^{[1]}X^T \\tag{5}$$\n",
        "\n",
        "\n",
        "$$db^{[1] } = \\frac{1}{m}\\sum_i dz^{[1]} \\tag{6}$$\n"
      ]
    },
    {
      "metadata": {
        "id": "uqB41MNdPDmh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def backward_propagation(parametros, cache, X, Y):\n",
        "    \"\"\"\n",
        "    Implementa el backward propagation \n",
        "    \n",
        "    Argumentos:\n",
        "    parametros  \n",
        "    cache -- dictionario con  \"Z1\", \"A1\", \"Z2\" and \"A2\".\n",
        "    X \n",
        "    Y  \n",
        "    \n",
        "    Returns:\n",
        "    grads -- python diccionario que contiene los gradientes \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    return grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zetahzehPDmm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Gradient descent \n",
        "\n",
        "$ \\theta = \\theta - \\alpha \\frac{\\partial J }{ \\partial \\theta }$ donde  $\\alpha$ es el learning rate y $\\theta$ representa un parametro.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DARXmR3ePDmm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def gradiente_descendiente(parametros, grads, learning_rate = 1.2):\n",
        "    \"\"\"\n",
        "    Encuentra los parametros que produzcan el minimo error\n",
        "    \n",
        "    Argumentos:\n",
        "    parameters  \n",
        "    grads  \n",
        "    \n",
        "    Returns:\n",
        "    parameters -- python diccionario con los parametros actualizados  \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6oiZpLd8PDms",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.4 - Integra  4.1, 4.2 y 4.3 en nn_model() ####\n"
      ]
    },
    {
      "metadata": {
        "id": "TVOneQq_PDms",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
        "    \"\"\"\n",
        "    Argumentos:\n",
        "    X --  Datos de entrenamineto\n",
        "    Y -- Variable a predecir\n",
        "    n_h -- Tamaño de la hidden layer\n",
        "    num_iterations \n",
        "    print_cost -- si es True, print imprime el cost cada 1000 iteraciones\n",
        "    \n",
        "    Returns:\n",
        "    parametros -- Parametros aprendidos \n",
        "    \"\"\"\n",
        "    \n",
        "    return parametros"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jH7g3x4MPDmz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4.5 Predicciones\n",
        "\n",
        "**Recordatorio**: predicciones = $y_{prediction} = \\mathbb 1 \\text{{activation > 0.5}} = \\begin{cases}\n",
        "      1 & \\text{if}\\ activation > 0.5 \\\\\n",
        "      0 & \\text{otherwise}\n",
        "    \\end{cases}$  \n",
        "    `"
      ]
    },
    {
      "metadata": {
        "id": "6-c5jR_SPDm0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def predict(parametros, X):\n",
        "    \"\"\"\n",
        "    \n",
        "    Argumentos:\n",
        "    parametros \n",
        "    X -- input data(n_x, m)\n",
        "    \n",
        "    Returns\n",
        "    predictions -- vector con  ( 0 / 1)\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    return predictions"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}