{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bidirectional_RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2eoEX4bDpYBB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bidirectional RNNs\n",
        "All the recurrent networks we have considered up to now have a “causal” struc-ture, meaning that the state at time **t**  captures only information from the past,$x^{1} , . . . ,  x^{t-1} $, and the present input $x^t$. Some of the models we have discussedalso allow information from past **y** values to aﬀect the current state when the **y** values are available.In many applications, however, we want to output a prediction of $y^t$ that may depend on the whole input sequence.\n",
        "\n",
        "For example, in speech recognition, the correct interpretation of the current sound as a phoneme may depend on the nextfew phonemes because of co-articulation and may even depend on the next few words because of the linguistic dependencies between nearby words: if there are two interpretations of the current word that are both acoustically plausible, we may have to look far into the future (and the past) to disambiguate them. This is also true of handwriting recognition and many other sequence-to-sequence learning tasks, described in the next section.\n",
        "\n",
        "Bidirectional recurrent neural networks (or bidirectional RNNs) were inventedto address that need\n",
        "![alt text](https://stanford.edu/~shervine/images/bidirectional-rnn.png)\n",
        "\n",
        "As the name suggests, bidirectional RNNs combine an RNN that moves forward through time, beginning from the start of the sequence, with another RNN that moves backward through time, beginning from the end of the sequence.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jiKgMXmo4Yrv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! pip3 install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-JYUtxzX44DI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modules"
      ]
    },
    {
      "metadata": {
        "id": "DRpBIgcq30PA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BylLrGhJ41cn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-dIr1iE4_8G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Hyper-parameters"
      ]
    },
    {
      "metadata": {
        "id": "hJOxx3aH47NB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequence_length = 28\n",
        "input_size = 28\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "num_epochs = 2\n",
        "learning_rate = 0.003\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kHT9hdJ-5E-A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ]
    },
    {
      "metadata": {
        "id": "4x51foLH5KJ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='data/',\n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='data/',\n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7k6ULVAQ5ScF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  Bidirectional recurrent neural network (many-to-one)\n"
      ]
    },
    {
      "metadata": {
        "id": "54TTmHpS5aMQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BiRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(BiRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Set initial states\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
        "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
        "        \n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U9l6Ppos5dbu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = BiRNN(input_size, hidden_size, num_layers, num_classes).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zIgSOHuu5gLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loss and optimizer"
      ]
    },
    {
      "metadata": {
        "id": "FS1tgiqC5kZ8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "crossentropy = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HUtbyX25oIw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train Model"
      ]
    },
    {
      "metadata": {
        "id": "qY1k5Lzf5sO5",
        "colab_type": "code",
        "outputId": "b086651e-23c3-4c2d-dcd0-3a404a323ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = crossentropy(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.5666\n",
            "Epoch [1/2], Step [200/600], Loss: 0.4634\n",
            "Epoch [1/2], Step [300/600], Loss: 0.1023\n",
            "Epoch [1/2], Step [400/600], Loss: 0.1456\n",
            "Epoch [1/2], Step [500/600], Loss: 0.2272\n",
            "Epoch [1/2], Step [600/600], Loss: 0.0968\n",
            "Epoch [2/2], Step [100/600], Loss: 0.0792\n",
            "Epoch [2/2], Step [200/600], Loss: 0.0621\n",
            "Epoch [2/2], Step [300/600], Loss: 0.0273\n",
            "Epoch [2/2], Step [400/600], Loss: 0.0372\n",
            "Epoch [2/2], Step [500/600], Loss: 0.0415\n",
            "Epoch [2/2], Step [600/600], Loss: 0.0362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pU0UuWua5sra",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test Model"
      ]
    },
    {
      "metadata": {
        "id": "hBICPC6o5vEc",
        "colab_type": "code",
        "outputId": "6083d170-966e-4efc-abf3-15c72887a484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 97.18 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qsxBRk6l52ep",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Save the model checkpoint"
      ]
    },
    {
      "metadata": {
        "id": "zbc033DK5zYu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ug8m6QqE58T_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}