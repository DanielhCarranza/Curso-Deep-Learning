{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Redes Neuronales Convoluciones Pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "JtVhwALKG6QX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks with Pytorch\n",
        "Convolutional neural networks, also known as CNNs, are a specific type of neural networks that are generally composed of the following layers\n",
        "![alt text](https://stanford.edu/~shervine/images/architecture-cnn.png)\n",
        "\n",
        "**Convolution layer (CONV)** ― The convolution layer (CONV) uses filters that perform convolution operations as it is scanning the input $I$ with respect to its dimensions. Its hyperparameters include the filter size $F$ and stride $S$. The resulting output $O$ is called *feature map* or *activation map*.\n",
        "![alt text](https://stanford.edu/~shervine/images/convolution-layer-a.png)\n",
        "*Remark: the convolution step can be generalized to the 1D and 3D cases as well.*\n",
        "\n",
        "**Pooling (POOL)** ― The pooling layer (POOL) is a downsampling operation, typically applied after a convolution layer, which does some spatial invariance. In particular, max and average pooling are special kinds of pooling where the maximum and average value is taken, respectively.\n",
        "* *Max pooling*: \n",
        "  Each pooling operation selects the maximum value of the current view\n",
        "  *  Preserves detected features\n",
        "  *  Most commonly used\n",
        "![alt text](https://stanford.edu/~shervine/images/max-pooling-a.png)\n",
        "\n",
        "* *Average pooling*: Each pooling operation averages the values of the current view\n",
        "  * Downsamples feature map\n",
        "  *  Used in LeNet\n",
        "  ![alt text](https://stanford.edu/~shervine/images/average-pooling-a.png)\n",
        "  \n",
        " **Fully Connected (FC)** ― The fully connected layer (FC) operates on a flattened input where each input is connected to all neurons. If present, FC layers are usually found towards the end of CNN architectures and can be used to optimize objectives such as class scores.\n",
        " ![alt text](https://stanford.edu/~shervine/images/fully-connected.png)\n",
        " \n",
        " References:\n",
        "  * [Convolutional Neural Networks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)\n",
        "  * [Convolutional Neural Networks](http://cs231n.github.io/convolutional-networks/)\n"
      ]
    },
    {
      "metadata": {
        "id": "BXgZXBo5L7Xn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Modules"
      ]
    },
    {
      "metadata": {
        "id": "Ub8wF44eHAkh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfpEkNKmHApG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dyEutTQUL-kF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hyper parameters"
      ]
    },
    {
      "metadata": {
        "id": "pCeRZ3CpHMVM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eRv-7bG3MDnB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "uvEl52KtHMZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                           train=True, \n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                          train=False, \n",
        "                                          transform=transforms.ToTensor())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AnjilVEtMHQ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data loader"
      ]
    },
    {
      "metadata": {
        "id": "ZQmvv67vHMdZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O2BnAdu0L6Nl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Convolutional neural network"
      ]
    },
    {
      "metadata": {
        "id": "6zPwAoUVHMhO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7*7*32, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9T7aA8MDHMk1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = ConvNet(num_classes).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2sOxf8HMMNjY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss and Optimizer"
      ]
    },
    {
      "metadata": {
        "id": "w0CypDj4HMpE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "crossentropy = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o5af8SrsMRS5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ]
    },
    {
      "metadata": {
        "id": "x_drjij0HMs7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = crossentropy(outputs, labels)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WYLZeR_YMTou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test the model"
      ]
    },
    {
      "metadata": {
        "id": "G3rA2VfdHMxb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H7ZzMHiIHM2Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-9RauVm0HAs7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}